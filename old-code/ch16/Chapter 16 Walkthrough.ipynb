{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16:Training neural networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Classifying data with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.1 Classifying images of handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.1 Building the 64-dimensional image vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec92cbc048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI, a way to overlay numbers on the pixels showing their brightness values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r)\n",
    "for i in range(0,8):\n",
    "    for j in range(0,8):\n",
    "        plt.gca().text(i-0.15,j,int(digits.images[0][j][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.flatten(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.33333333, 0.86666667, 0.6       ,\n",
       "       0.06666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.86666667, 1.        , 0.66666667, 1.        , 0.33333333,\n",
       "       0.        , 0.        , 0.2       , 1.        , 0.13333333,\n",
       "       0.        , 0.73333333, 0.53333333, 0.        , 0.        ,\n",
       "       0.26666667, 0.8       , 0.        , 0.        , 0.53333333,\n",
       "       0.53333333, 0.        , 0.        , 0.33333333, 0.53333333,\n",
       "       0.        , 0.        , 0.6       , 0.53333333, 0.        ,\n",
       "       0.        , 0.26666667, 0.73333333, 0.        , 0.06666667,\n",
       "       0.8       , 0.46666667, 0.        , 0.        , 0.13333333,\n",
       "       0.93333333, 0.33333333, 0.66666667, 0.8       , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4       , 0.86666667,\n",
       "       0.66666667, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.flatten(digits.images[0]) / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.2 Building a random digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(input_vector):\n",
    "    return np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09609494, 0.75660412, 0.78242862, 0.43881297, 0.33470396,\n",
       "       0.92745083, 0.9695724 , 0.12471611, 0.01307655, 0.61261849])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.matrix.flatten(digits.images[0]) / 15.\n",
    "result = random_classifier(v)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** because this is random, you will get a different digit result when you re-run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result).index(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.3 Measuring performance of the digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_digit_classify(classifier,test_count=1000):\n",
    "    correct = 0 #<1>\n",
    "    for img, target in zip(digits.images[:test_count], digits.target[:test_count]): #<2>\n",
    "        v = np.matrix.flatten(img) / 15. #<3>\n",
    "        output = classifier(v) #<4>\n",
    "        answer = list(output).index(max(output)) #<5>\n",
    "        if answer == target:\n",
    "            correct += 1 #<6>\n",
    "    return (correct/test_count) #<7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.089"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(random_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Suppose a digit classifier function outputs the following NumPy array.  What digit does it think the image represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00512567e-06, 3.94168539e-05, 5.57124430e-09, 9.31981207e-09,\n",
       "       9.98060276e-01, 9.10328786e-07, 1.56262695e-03, 1.82976466e-04,\n",
       "       1.48519455e-04, 2.54354113e-07])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5.00512567e-06, 3.94168539e-05, 5.57124430e-09, 9.31981207e-09,\n",
    "       9.98060276e-01, 9.10328786e-07, 1.56262695e-03, 1.82976466e-04,\n",
    "       1.48519455e-04, 2.54354113e-07])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini project:** Find the average of all the images of nines in the data set, in the same way we took averages of images in Chapter 6.  Plot the resulting image. What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_img(i):\n",
    "    imgs = [img for img,target in zip(digits.images[1000:], digits.target[1000:]) if target==i]\n",
    "    return sum(imgs) / len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b926891c50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(average_img(9), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini project:** Build a better classifier than a random one by finding the average image of each kind of digit in the test data set, and comparing a target image with all of the averages.  Specifically, return a vector of the dot products of the target image with each average digit image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_digits = [np.matrix.flatten(average_img(i)) for i in range(10)]\n",
    "def compare_to_avg(v):\n",
    "    return [np.dot(v,avg_digits[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(compare_to_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.2 Designing a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.1 Organizing neurons and connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.2 Data flow through a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.3 Calculating activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.4 Calculating activations in matrix notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.3 Building a neural network in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.1 Implementing an MLP class in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self,layer_sizes): #<1>\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = [\n",
    "            np.random.rand(n,m) #<2>\n",
    "            for m,n in zip(layer_sizes[:-1],layer_sizes[1:]) #<3>\n",
    "        ]\n",
    "        self.biases = [np.random.rand(n) for n in layer_sizes[1:]] #<4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP([2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** these numbers are randomly initialized, so your results below will vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04098182, 0.61121605],\n",
       "        [0.99402839, 0.43278994],\n",
       "        [0.14826355, 0.39370373]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.62871743, 0.55151304, 0.91445791])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.2 Evaluating the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self,layer_sizes): #<1>\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = [\n",
    "            np.random.rand(n,m) #<2>\n",
    "            for m,n in zip(layer_sizes[:-1],layer_sizes[1:]) #<3>\n",
    "        ]\n",
    "        self.biases = [np.random.rand(n) for n in layer_sizes[1:]] #<4>\n",
    "    def feedforward(self,v):\n",
    "        activations = [] #<1>\n",
    "        a = v\n",
    "        activations.append(a) #<2>\n",
    "        for w,b in zip(self.weights, self.biases): #<3>\n",
    "            z = w @ a + b #<4>\n",
    "            a = [sigmoid(x) for x in z] #<5>\n",
    "            activations.append(a) #<6>\n",
    "        return activations\n",
    "    def evaluate(self,v):\n",
    "        return np.array(self.feedforward(v)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.3 Testing the classification performance of an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP([64,16,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.matrix.flatten(digits.images[0]) / 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99996588, 0.99829151, 0.99979785, 0.9998958 , 0.99991507,\n",
       "       0.99982444, 0.9999176 , 0.99863889, 0.99977906, 0.99887847])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.099"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(nn.evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.4 Training a neural network using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.1 Framing training as a minimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.2 Calculating gradients with backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.3 Automatic training with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([np.matrix.flatten(img) for img in digits.images[:1000]]) / 15.0\n",
    "y = digits.target[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,), #<1>\n",
    "                    activation='logistic', #<2>\n",
    "                    max_iter=100, #<3>\n",
    "                    verbose=10, #<4>\n",
    "                    random_state=1, #<5>\n",
    "                    learning_rate_init=.1) #<6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.21958598\n",
      "Iteration 2, loss = 1.56912978\n",
      "Iteration 3, loss = 0.98970277\n",
      "Iteration 4, loss = 0.57473464\n",
      "Iteration 5, loss = 0.34048448\n",
      "Iteration 6, loss = 0.21495855\n",
      "Iteration 7, loss = 0.14366771\n",
      "Iteration 8, loss = 0.11077020\n",
      "Iteration 9, loss = 0.08764273\n",
      "Iteration 10, loss = 0.07193546\n",
      "Iteration 11, loss = 0.06020348\n",
      "Iteration 12, loss = 0.04961899\n",
      "Iteration 13, loss = 0.03979645\n",
      "Iteration 14, loss = 0.03334502\n",
      "Iteration 15, loss = 0.02996006\n",
      "Iteration 16, loss = 0.02603968\n",
      "Iteration 17, loss = 0.02355514\n",
      "Iteration 18, loss = 0.02137348\n",
      "Iteration 19, loss = 0.01967878\n",
      "Iteration 20, loss = 0.01751214\n",
      "Iteration 21, loss = 0.01617330\n",
      "Iteration 22, loss = 0.01460386\n",
      "Iteration 23, loss = 0.01408517\n",
      "Iteration 24, loss = 0.01270504\n",
      "Iteration 25, loss = 0.01191634\n",
      "Iteration 26, loss = 0.01114222\n",
      "Iteration 27, loss = 0.01045989\n",
      "Iteration 28, loss = 0.00983648\n",
      "Iteration 29, loss = 0.00920912\n",
      "Iteration 30, loss = 0.00890851\n",
      "Iteration 31, loss = 0.00843426\n",
      "Iteration 32, loss = 0.00796039\n",
      "Iteration 33, loss = 0.00749839\n",
      "Iteration 34, loss = 0.00726271\n",
      "Iteration 35, loss = 0.00673963\n",
      "Iteration 36, loss = 0.00655405\n",
      "Iteration 37, loss = 0.00626207\n",
      "Iteration 38, loss = 0.00600639\n",
      "Iteration 39, loss = 0.00581857\n",
      "Iteration 40, loss = 0.00557529\n",
      "Iteration 41, loss = 0.00533573\n",
      "Iteration 42, loss = 0.00519479\n",
      "Iteration 43, loss = 0.00505128\n",
      "Iteration 44, loss = 0.00490121\n",
      "Iteration 45, loss = 0.00469161\n",
      "Iteration 46, loss = 0.00459590\n",
      "Iteration 47, loss = 0.00464844\n",
      "Iteration 48, loss = 0.00445157\n",
      "Iteration 49, loss = 0.00425515\n",
      "Iteration 50, loss = 0.00424934\n",
      "Iteration 51, loss = 0.00397800\n",
      "Iteration 52, loss = 0.00399927\n",
      "Iteration 53, loss = 0.00383932\n",
      "Iteration 54, loss = 0.00372439\n",
      "Iteration 55, loss = 0.00361744\n",
      "Iteration 56, loss = 0.00356447\n",
      "Iteration 57, loss = 0.00345899\n",
      "Iteration 58, loss = 0.00336792\n",
      "Iteration 59, loss = 0.00330330\n",
      "Iteration 60, loss = 0.00321734\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(16,), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=100, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=10,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99766643e-01, 8.43331208e-11, 3.47867059e-06, 1.49956270e-07,\n",
       "       1.88677660e-06, 3.44652605e-05, 6.23829017e-06, 1.09043503e-04,\n",
       "       1.11195821e-07, 7.79837557e-05])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp._predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_trained_classify(v):\n",
    "    return mlp._predict([v])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(sklearn_trained_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Modify the `test_digit_classify` function to work on a custom range of examples in the test set.  How does it do on the next 500 examples after the 1,000 training examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_digit_classify(classifier,start=0,test_count=1000):\n",
    "    correct = 0\n",
    "    end = start + test_count #<1>\n",
    "    for img, target in zip(digits.images[start:end], digits.target[start:end]): #<2>\n",
    "        v = np.matrix.flatten(img) / 15.\n",
    "        output = classifier(v)\n",
    "        answer = list(output).index(max(output))\n",
    "        if answer == target:\n",
    "            correct += 1\n",
    "    return (correct/test_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(sklearn_trained_classify,start=1000,test_count=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using the squared distance cost function, what is the cost of your randomly-generated MLP for the first 1,000 training examples?  What is the cost of the scikit-learn MLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_vec(digit):\n",
    "    return np.array([1 if i == digit else 0 for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_one(classifier,x,i):\n",
    "    return sum([(classifier(x)[j] - y_vec(i)[j])**2 for j in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(classifier):\n",
    "    return sum([cost_one(classifier,x[j],y[j]) for j in range(1000)])/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.990834701722013"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost(nn.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.670512721637246e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost(sklearn_trained_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-project:** Extract the MLPClassifier weights and biases using its properties called `coefs_` and `intercepts_`, respectively.  Plug these weights and biases into the MLP class we built from scratch and show that your resulting MLP performs well on digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP([64,16,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.weights = [w.T for w in mlp.coefs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.biases = mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(nn.evaluate,start=1000,test_count=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.5 Calculating gradients with backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.1 Finding the cost in terms of the last layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.1 Finding the cost in terms of the last layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.2 Calculating the partial derivatives for the last layer weights using the chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.3 Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-project:** Use SymPy or your own code from chapter 10 to automatically find the derivative of the sigmoid function:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Show that the answer you get is equal to $\\sigma(x)(1-\\sigma(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp(-x)/(1 + exp(-x))**2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "X = symbols('x')\n",
    "diff(1 / (1+exp(-X)),X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
